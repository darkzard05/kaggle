{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle 타이타닉 문제는 타이타닉의 승객 중에 생존 유무를 예측하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numpy, Pandas 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 시각화 라이브러리 불러오기\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 사이킷런 머신러닝 라이브러리 불러오기\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/python/titanic/train.csv')\n",
        "test = pd.read_csv('/python/titanic/test.csv')\n",
        "total = [train, test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  \n--------------------\n       PassengerId      Pclass         Age       SibSp       Parch        Fare\ncount   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\nmean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\nstd     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\nmin     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\nmax    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
          ]
        }
      ],
      "source": [
        "# 전체 데이터에 대한 요약\n",
        "print(train.describe())\n",
        "print('-'*20)\n",
        "print(test.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n--------------------\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Training, Test 세트의 결측치 확인하기\n",
        "print(train.isnull().sum())\n",
        "print('-'*20)\n",
        "print(test.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   SibSp  Survived\n1      1  0.535885\n2      2  0.464286\n0      0  0.345395\n3      3  0.250000\n4      4  0.166667\n5      5  0.000000\n6      8  0.000000\n--------------------\n   Parch  Survived\n3      3  0.600000\n1      1  0.550847\n2      2  0.500000\n0      0  0.343658\n5      5  0.200000\n4      4  0.000000\n6      6  0.000000\n--------------------\n   Pclass  Survived\n0       1  0.629630\n1       2  0.472826\n2       3  0.242363\n--------------------\n      Sex  Survived\n0  female  0.742038\n1    male  0.188908\n"
          ]
        }
      ],
      "source": [
        "# 카테고리형 특성들의 생존율과의 연관성을 살펴본다.\n",
        "print(train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
        "print('-'*20)\n",
        "print(train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
        "print('-'*20)\n",
        "print(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n",
        "print('-'*20)\n",
        "print(train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A/5 21171PC 17599STON/O2. 310128211380337345033087717463349909347742237736PP 9549113783A/5. 21513470823504062487063826522443733457632649239865248698330923113788349909347077263119950330959349216PC 17601PC 17569335677C.A. 24579PC 176041137892677A./5. 21523457642651754611668349253SC/Paris 2123330958S.C./A.4. 235673703711431126623492373101295A/4. 39886PC 17572292611350919947C.A. 310262697C.A. 34651CA 2144266911357236973347088PC 176052661C.A. 29395S.P. 34643101281315151C.A. 33111CA 2144S.O.C. 1487926801601348123349208374746248738364516345767345779330932113059SO/C 148853101278W./C. 6608SOTON/OQ 39208619950343275343276347466W.E.P. 5734C.A. 2315364500374910PC 17754PC 177592319192443673492453492153528175403101276349207343120312991349249371110110465266532466941362627STON/O 2. 310129437036911668PC 17558347082S.O.C. 14879A4. 5451023773627267352812651370372C 173692668347061349241SOTON/O.Q. 3101307A/5. 3337228414C.A. 29178SC/PARIS 2133117521138037534PC 175932678347081STON/O2. 3101279365222231945C.A. 33112350043W./C. 6608230080244310S.O.P. 1166113776A.5. 11206A/5. 851Fa 265302PC 1759735851SOTON/OQ 392090315037CA. 2343371362C.A. 335953470683150933101295363291113505347088PC 173181601111240382652347742STON/O 2. 3101280177643504044133PC 17595250653LINECA. 2343SC/PARIS 213134707723013631515311376737036511142836484934924723460428424350046230080PC 17610PC 175693687034579370370248747345770CA. 234331012642628A/5 354034705431012782699367231112277SOTON/O.Q. 3101311F.C.C. 13528A/5 2117425064636722935273STON/O2. 310128324384711813W/C 14208SOTON/OQ 3920892203672144034923419943PP 4348SW/PP 751A/5 21173236171413336973347067237442347077C.A. 29566W./C. 660926707C.A. 3192128665SCO/W 15852665367230W./C. 14263STON/O 2. 310127526941992834707125064911751244252362316347054113514A/5. 33363701292650PC 17585110152PC 17755230433384461347077110413112059382649C.A. 172483101295347083PC 17582PC 17760113798LINE250644PC 1759637037513502347073239853382652C.A. 2673336439347464345778A/5. 104821130563492393457743492062377983703731987711967SC/Paris 2163349236349233PC 17612269311378119988PC 175589234367226LINE226593A/5 246611378117421PC 17758P/PP 3381PC 1748511767PC 17608250651349243F.C.C. 13529347470244367290113692816966A/5 21172349219234818248738CA. 2343PC 1776034536428551363291111361367226113043PC 17582345764PC 176113492251137761696675981137842300801995024874024436122923624873331418386525C.A. 37671315088726711351026953492372647345783113505237671330931330980347088SC/PARIS 21672691SOTON/O.Q. 3101310370365C 7076110813262614313PC 17477117653101267323951PC 17760349909PC 17604C 70771135032648347069PC 177572653STON/O 2. 3101293113789349227S.O.C. 14879CA 214427849367655SC 1748113760350034310127735273PP 954935005235040728403244278240929STON/O 2. 31012893418264137STON/O2. 31012793150962866434706429106312992413334922239414019928239853STON/O 2. 31012693430952822025065228228345773349254A/5. 13032315082347080370129A/4. 342442003250655364851SOTON/O.Q. 392078110564376564SC/AH 3085STON/O 2. 310127413507113760W./C. 66082910619950C.A. 18723F.C.C. 1352934576934707623043465306336382506441137942666113786C.A. 346516530311305117453A/5 28173492401350917464F.C.C. 1353137106019952364506111320234360A/S 2816SOTON/O.Q. 3101306239853113792362092666323592315089C.A. 34651SC/AH Basle 54175531104653102734603500603101298CA 2144239854A/5 359441341196741331994311771A.5. 18509C.A. 3767165304SOTON/OQ 3101317113787PC 17609A/4 45380262736947C.A. 62121137813500353150863648463309094135110152PC 1775826360111427C 40011601382651SOTON/OQ 3101316PC 17473PC 1760334920936967C.A. 342603711102268753492421274934925226241113612700367232W./C. 14258PC 1748331012962910426360264126902668315084F.C.C. 13529113050PC 1776136449813568WE/P 57353470823470822908PC 177616932908SC/PARIS 2146363291C.A. 3311217421244358330979262034708511380711755PC 17757110413345572372622349251218629SOTON/OQ 392082SOTON/O.Q. 392087A/4 488713492053499092686350417S.W./PP 75211769PC 1747414312A/4. 20589358585243880135072689STON/O 2. 310128623778917421284031304934111104132375651356714973A./5. 3235STON/O 2. 310127336947A/5 3902364848SC/AH 29037345773248727LINE2664PC 17485243847349214113796364511111426349910349246113804SC/Paris 2123PC 17582347082SOTON/O.Q. 3101305367230370377364512220845347080A/5. 33362301363102826591175326533500295463636963219533135023492243349122704234774313214112052347088237668STON/O 2. 3101292C.A. 319213101295376564350050PC 1747734708816012666PC 1757234923113213S.O./P.P. 751CA. 23143492212319198475330919365226S.O.C. 148793492233648492975135273PC 1761126235727349210STON/O 2. 3101285S.O.C. 14879234686312993A/5 35361999629750F.C. 12750C.A. 245802442702398563499123428264138CA 2144PC 17755330935PC 175726563CA 214429750SC/Paris 212331012953492283500362416017474349256160126721138002487313635923585217421348121PC 17757PC 17475269136864350025250655223596PC 174761137812661PC 17482113028199967545250647348124PC 177573421836568347062248727350048122332506431138063150943102736866236853STON/O2. 31012712416026992398552842523363954636W./C. 6608PC 177553492013492181698819877PC 17608376566STON/O 2. 3101288WE/P 5735C.A. 26732506481137733350972910339209634578034920422084525064935004229108363294110152358585SOTON/O2 31012722663113760347074135021123793648503711108471345781350047S.O./P.P. 32674291053470783831213645163686524160268717474113501W./C. 6607SOTON/O.Q. 31013123748873101265382652C.A. 2315PC 1759312460239865CA. 2343PC 1760034920328213174653492442685345773250647C.A. 3192111376026253470893470631120503470872487231138063474A/4 4887128206347082364499112058STON/O2. 3101290S.C./PARIS 2079C 7075347088127493150981997239209631012953683231601S.C./PARIS 207936722811357226592910626713474682223PC 17756315097392092160111774SOTON/O2 3101287S.O./P.P. 31137982683315090C.A. 5547CA. 2343349213248727174533470823470602678PC 1759224425239209136928113055266626293500262813417466CA. 2343233866236852SC/PARIS 2149PC 1759034577734774234924811751695345765P/PP 338126677534349212349217117672304333492577552C.A./SOTON 34068SOTON/OQ 392076382652211536112053W./C. 6607111369370376\n"
          ]
        }
      ],
      "source": [
        "print(train['Ticket'])\n",
        "# Ticket에서는 유의미한 특성을 찾아내지 못해서 Ticket을 제거합니다.\n",
        "for data in total:\n",
        "    data.drop(['Ticket'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cabin을 알파벳 첫번째 글자로 구분하고 Pclass 기준으로 중간값으로 결측치를 채웁니다.\n",
        "for data in total:\n",
        "    data['Cabin'] = data['Cabin'].str[:1]\n",
        "    data['Cabin'] = data['Cabin'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'T': 7})\n",
        "    data['Cabin'].fillna(data.groupby('Pclass')['Cabin'].transform('median'), inplace=True)\n",
        "\n",
        "for data in total:\n",
        "    data.drop(['Cabin'], axis=1, inplace=True)\n",
        "\n",
        "# Name에서 Title으로 추출해서 구분한다.\n",
        "for data in total:\n",
        "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "# sns.countplot(data=train, x='Title', hue='Survived')\n",
        "# print(pd.crosstab(train['Title'], train['Sex']))\n",
        "\n",
        "for data in total:\n",
        "    data['Title'] = data['Title'].replace(['Lady', 'Countess', 'Capt', 'Col',\\\n",
        "        'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'others')\n",
        "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
        "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "# print(train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n",
        "\n",
        "for data in total:\n",
        "    data['Title'] = data['Title'].astype('category').cat.codes\n",
        "    data.drop(['Name'], axis=1, inplace=True)\n",
        "\n",
        "# Fare 결측치를 채우고 분위수 기준으로 구간을 나눈다.\n",
        "for data in total:\n",
        "    data['Fare'].fillna(data.groupby('Pclass')['Fare'].transform('median'), inplace=True)\n",
        "    data['Fare'] = pd.qcut(data['Fare'], 10, labels=False)\n",
        "\n",
        "# Age의 결측치를 Title을 기준으로 중간값으로 채운다.\n",
        "for data in total:\n",
        "    data['Age'].fillna(data.groupby('Title')['Age'].transform('median'), inplace=True)\n",
        "    \n",
        "# Sex를 0과 1로 나눕니다.\n",
        "for data in total:\n",
        "    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
        "\n",
        "# Age를 구간을 임의로 나눠서 분류한다.\n",
        "for data in total:\n",
        "    data['Age'] = pd.cut(data['Age'], [0, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 100], labels=False)\n",
        "\n",
        "# 본인이 속한 가족구성원의 수를 FamilySize에 저장한다.\n",
        "for data in total:\n",
        "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
        "\n",
        "# print(train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False)\\\n",
        "#         .mean().sort_values(by='Survived', ascending=False))\n",
        "\n",
        "# 핵가족인 경우는 1, 아니면 0이다.\n",
        "for data in total:\n",
        "    data['Nuclear'] = 0\n",
        "    data.loc[(2 <= data['FamilySize']) & (data['FamilySize'] <= 4), 'Nuclear'] = 1\n",
        "\n",
        "# 불필요해진 특성인 FamilySize는 지운다.\n",
        "for data in total:\n",
        "    data.drop('FamilySize', axis=1, inplace=True)\n",
        "\n",
        "# print(train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
        "\n",
        "# 출발항 결측치는 가장 많은 출발항 S로 채운다.\n",
        "train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\n",
        "\n",
        "for data in total:\n",
        "    data['Embarked'] = data['Embarked'].astype('category').cat.codes\n",
        "\n",
        "X_train = train.drop(['PassengerId', 'Survived'], axis=1)\n",
        "Y_train = train['Survived']\n",
        "X_test = test.drop('PassengerId', axis=1).copy()\n",
        "\n",
        "# print(X_train, Y_train, X_test, sep='\\n')\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "# 다양한 머신러닝 모델을 적용해서 교차 검증 점수로 순위를 매긴다.\n",
        "perceptron = Perceptron(random_state=1)\n",
        "perceptron.fit(X_train, Y_train)\n",
        "score_perceptron = round(cross_val_score(perceptron, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('Perceptron의 교차 검증 점수 : {}.'.format(score_perceptron))\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, Y_train)\n",
        "score_gnb = round(cross_val_score(gnb, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('GaussainNB의 교차 검증 점수 : {}'.format(score_gnb))\n",
        "\n",
        "logreg = LogisticRegression(max_iter=2000, random_state=1)\n",
        "logreg.fit(X_train, Y_train)\n",
        "score_logreg = round(cross_val_score(logreg, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('로지스틱회귀의 교차 검증 점수 : {}'.format(score_logreg))\n",
        "\n",
        "linear_svc = LinearSVC(max_iter=10000, random_state=1)\n",
        "linear_svc.fit(X_train, Y_train)\n",
        "score_linear_svc = round(cross_val_score(linear_svc, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('LinearSVC의 교차 검증 점수 : {}'.format(score_linear_svc))\n",
        "\n",
        "svc = SVC(random_state=1)\n",
        "svc.fit(X_train, Y_train)\n",
        "score_svc = round(cross_val_score(svc, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('SVC의 교차 검증 점수 : {}'.format(score_svc))\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, Y_train)\n",
        "score_knn = round(cross_val_score(knn, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('KNN의 교차 검증 점수 : {}'.format(score_knn))\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(random_state=1)\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "score_decision_tree = round(cross_val_score(decision_tree, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('결정트리의 교차 검증 점수 : {}'.format(score_decision_tree))\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=50, max_depth=1, max_features=3, random_state=1)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "score_random_forest = round(cross_val_score(random_forest, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('랜덤포레스트의 교차 검증 점수 : {}'.format(score_random_forest))\n",
        "\n",
        "gbc = GradientBoostingClassifier(max_depth=1, max_features=3, random_state=1)\n",
        "gbc.fit(X_train, Y_train)\n",
        "score_gbc = round(cross_val_score(gbc, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('그래디언트부스팅분류의 교차 검증 점수 : {}'.format(score_gbc))\n",
        "\n",
        "mlp = MLPClassifier(max_iter=1000, random_state=1)\n",
        "mlp.fit(X_train, Y_train)\n",
        "score_mlp = round(cross_val_score(mlp, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('MLP의 교차 검증 점수 : {}'.format(score_mlp))\n",
        "\n",
        "sgd = SGDClassifier(random_state=1)\n",
        "sgd.fit(X_train, Y_train)\n",
        "score_sgd = round(cross_val_score(sgd, X_train, Y_train, cv=cv).mean() * 100, 3)\n",
        "print('SGD의 교차 검증 점수 : {}'.format(score_sgd))\n",
        "\n",
        "models = pd.DataFrame([['Perceptron', score_perceptron, perceptron],\\\n",
        "                      ['GaussianNB', score_gnb, gnb], ['KNN', score_knn, knn],\\\n",
        "                      ['Random Forest', score_random_forest, random_forest],\\\n",
        "                      ['Decision Tree', score_decision_tree, decision_tree],\\\n",
        "                      ['Gradient Boosting Classifier', score_gbc, gbc],\\\n",
        "                      ['MLP', score_mlp, mlp], ['Linear SVC', score_linear_svc, linear_svc],\\\n",
        "                      ['Stochastic Gradient Decent', score_sgd, sgd],\\\n",
        "                      ['Logistic Regression', score_logreg, logreg], ['SVC', score_svc, svc]],\\\n",
        "                    columns=['Model', 'Score', 'Estimator'])\n",
        "sorted_models = models.sort_values(by=['Score'], axis=0, ascending=False, ignore_index=True).loc[:,['Model','Score']]\n",
        "best_estimator = models.sort_values(by=['Score'], axis=0, ascending=False, ignore_index=True).loc[:,['Estimator','Score']]\n",
        "print(sorted_models)\n",
        "print('교차 검증 점수가 가장 높은 모델은 {}이고 점수는 {}이다'.format(sorted_models.iloc[0, 0], sorted_models.iloc[0, 1]))\n",
        "Y_pred = best_estimator.iloc[0, 0].predict(X_test)\n",
        "\n",
        "# 그리드서치나 랜덤서치로 하이퍼파라미터를 세부적으로 조정한다.\n",
        "# svc = SVC(random_state=1)\n",
        "# parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\\\n",
        "#               'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\\\n",
        "#               'degree': [1, 2, 3, 4, 5, 6]}\n",
        "# grid_svc = GridSearchCV(svc, param_grid=parameters, cv=cv, n_jobs=-1, verbose=3)\n",
        "# grid_svc.fit(X_train, Y_train)\n",
        "# score_grid_svc = pd.DataFrame(grid_svc.cv_results_)\n",
        "# print(score_grid_svc[['params', 'mean_test_score', 'rank_test_score',\\\n",
        "#                            ]])\n",
        "# print('SVC의 그리드서치 최고 모델: {}'.format(grid_svc.best_estimator_))\n",
        "# print('SVC의 그리드서치 최고 파라미터: {}'.format(grid_svc.best_params_))\n",
        "# print('SVC의 그리츠서치 최고 정확도: {0:.3f}'.format(round(grid_svc.best_score_ * 100, 3)))\n",
        "# estimator = grid_svc.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# adaboost = AdaBoostClassifier(random_state=1)\n",
        "# parameters = {'n_estimators': [50, 100, 150, 200, 300],\\\n",
        "#               'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]}\n",
        "# grid_adaboost = GridSearchCV(adaboost, param_grid=parameters, cv=Kfold, n_jobs=-1, verbose=3)\n",
        "# grid_adaboost.fit(X_train, Y_train)\n",
        "# score_grid_adaboost = pd.DataFrame(grid_adaboost.cv_results_)\n",
        "# print(score_grid_adaboost[['params', 'mean_test_score', 'rank_test_score',\\\n",
        "#                            ]])\n",
        "# print('AdaBoost의 그리드서치 최고 모델: {}'.format(grid_adaboost.best_estimator_))\n",
        "# print('AdaBoost의 그리드서치 최고 파라미터: {}'.format(grid_adaboost.best_params_))\n",
        "# print('AdaBoost의 그리츠서치 최고 정확도: {0:.3f}'.format(round(grid_adaboost.best_score_ * 100, 3)))\n",
        "# estimator = grid_adaboost.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss',\\\n",
        "#                     silent=1, random_state=1)\n",
        "# parameters = {'n_estimators': [10, 20, 50, 100, 200, 500], 'max_depth': [1, 2, 3, 4, 5],\\\n",
        "#               'learing_rate': [0.001, 0.01, 0.1], 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1]}\n",
        "# grid_xgb = GridSearchCV(xgb, param_grid=parameters, cv=Kfold, n_jobs=-1)\n",
        "# grid_xgb.fit(X_train, Y_train, early_stopping_rounds=100, eval_set= [(X_train, Y_train)])\n",
        "# score_grid_xgb = pd.DataFrame(grid_xgb.cv_results_)\n",
        "# print(score_grid_xgb[['params', 'mean_test_score', 'rank_test_score',\\\n",
        "#                            ]])\n",
        "# print('XGB의 그리드서치 최고 모델: {}'.format(grid_xgb.best_estimator_))\n",
        "# print('XGB의 그리드서치 최고 파라미터: {}'.format(grid_xgb.best_params_))\n",
        "# print('XGB의 그리츠서치 최고 정확도: {0:.3f}'.format(round(grid_xgb.best_score_ * 100, 3)))\n",
        "# estimator = grid_xgb.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# random_forest = RandomForestClassifier(random_state=1)\n",
        "# parameters = {'max_depth': [1, 2, 3, 4, None], 'max_features': [1, 2, 3, 4, 'auto', 'sqrt', 'log2'],\\\n",
        "#               'n_estimators': [20, 50, 100],\n",
        "#               'min_samples_leaf': [1, 2, 3, 4],\\\n",
        "#               'min_samples_split': [2, 3, 4]}\n",
        "# grid_random_forest = GridSearchCV(random_forest, param_grid=parameters, cv=Kfold, n_jobs=-1, verbose=3)\n",
        "# grid_random_forest.fit(X_train, Y_train)\n",
        "# score_random_forest = pd.DataFrame(grid_random_forest.cv_results_)\n",
        "# print(score_random_forest[['params', 'mean_test_score', 'rank_test_score',\\\n",
        "#                            ]])\n",
        "# print('랜덤 포레스트의 그리드서치 최고 모델: {}'.format(grid_random_forest.best_estimator_))\n",
        "# print('랜덤 포레스트의 그리드서치 최고 파라미터: {}'.format(grid_random_forest.best_params_))\n",
        "# print('랜덤 포레스트의 그리츠서치 최고 정확도: {0:.3f}'.format(round(grid_random_forest.best_score_ * 100, 3)))\n",
        "# estimator = grid_random_forest.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# random_forest = RandomForestClassifier(random_state=1)\n",
        "# parameters = {'criterion': ['entropy', 'gini'],\\\n",
        "#               'max_depth': np.arange(1, 3, 1),\\\n",
        "#               'max_features': np.arange(1, 7, 1),\\\n",
        "#               'max_leaf_nodes': np.arange(5, 10, 1),\\\n",
        "#               'min_samples_leaf': np.arange(5, 10, 1),\\\n",
        "#               'min_samples_split': np.arange(5, 10, 1),\\\n",
        "#               'n_estimators': np.arange(5, 100, 5)}\n",
        "# rs_random_forest = RandomizedSearchCV(random_forest, n_iter=100, param_distributions=parameters,\\\n",
        "#                                       cv=cv, random_state=1, n_jobs=-1, verbose=3)\n",
        "# rs_random_forest.fit(X_train, Y_train)\n",
        "# score_random_forest = pd.DataFrame(rs_random_forest.cv_results_)\n",
        "# print(score_random_forest[['params', 'mean_test_score', 'rank_test_score']])\n",
        "# print('랜덤 포레스트의 랜덤서치 최고 파라미터: {}'.format(rs_random_forest.best_params_))\n",
        "# print('랜덤 포레스트의 랜덤서치 최고점수: {0:.3f}'.format(round(rs_random_forest.best_score_ * 100, 3)))\n",
        "# estimator = rs_random_forest.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# gbc = GradientBoostingClassifier(random_state=1)\n",
        "# parameters = {'learning_rate': [(0.1) ** n for n in range(10)],\\\n",
        "#               'n_estimators': np.arange(10, 5000, 10),\\\n",
        "#               'max_depth': np.arange(1, 20, 1),\\\n",
        "#               'max_features': np.arange(1, 9, 1),\\\n",
        "#               'min_samples_leaf': np.arange(1, 10, 1),\\\n",
        "#               'min_samples_split': np.arange(2, 10, 1),\\\n",
        "#               }\n",
        "# random_gbc = RandomizedSearchCV(gbc, n_iter=100, param_distributions=parameters, cv=Kfold, verbose=2, n_jobs=-1, refit=True)\n",
        "# random_gbc.fit(X_train, Y_train)\n",
        "# score_random_gbc = pd.DataFrame(random_gbc.cv_results_)\n",
        "# print(score_random_gbc[['params', 'mean_test_score', 'rank_test_score'\\\n",
        "#                  ]])\n",
        "# print('GBC의 랜덤서치 최고 모델: {}'.format(random_gbc.best_estimator_))\n",
        "# print('GBC의 랜덤서치 최적 파라미터: {}'.format(random_gbc.best_params_))\n",
        "# print('GBC의 랜덤서치 최고점수: {}'.format(round(random_gbc.best_score_ * 100, 3)))\n",
        "# estimator = random_gbc.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# mlp = MLPClassifier(max_iter=10000, hidden_layer_sizes=(100, 100), random_state=1)\n",
        "# parameters = {'alpha': [(0.1) ** i for i in range(1, 5)],\\\n",
        "#               'activation': ['logistic', 'adam', 'lbfgs']}\n",
        "# grid_mlp = GridSearchCV(mlp, param_grid=parameters, verbose=2, cv=Kfold, n_jobs=-1, refit=True)\n",
        "# grid_mlp.fit(X_train, Y_train)\n",
        "# score_mlp = pd.DataFrame(grid_mlp.cv_results_)\n",
        "# print(score_mlp[['params', 'mean_test_score', 'rank_test_score']])\n",
        "# print('MLP의 그리드서치 최적 파라미터: {}'.format(grid_mlp.best_params_))\n",
        "# print('MLP의 그리드서치 최고점수: {0:.3f}'.format(round(grid_mlp.best_score_ * 100, 3)))\n",
        "# estimator = grid_mlp.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# mlp = MLPClassifier(hidden_layer_sizes=(100))\n",
        "# parameters = {'alpha': [(0.1) ** n for n in range(10)],\\\n",
        "#                'solver': ['sgd', 'adam'],\\\n",
        "#                'activation': ['tanh', 'relu', 'logistic'],\\\n",
        "#                'max_iter': np.arange(10, 1000, 10),\\\n",
        "#                'batch_size': np.arange(1, 10, 1)}\n",
        "# random_mlp = RandomizedSearchCV(mlp, param_distributions=parameters, random_state=1,\\\n",
        "#                                 n_iter=10, n_jobs=-1, cv=cv, verbose=3)\n",
        "# random_mlp.fit(X_train, Y_train)\n",
        "# score_random_mlp = pd.DataFrame(random_mlp.cv_results_)\n",
        "# print(score_random_mlp[['params', 'mean_test_score', 'rank_test_score'\\\n",
        "#                         ]])\n",
        "# print('MLP의 랜덤서치 최적 파라미터: {}'.format(random_mlp.best_params_))\n",
        "# print('MLP의 랜덤서치 최고점수: {0:.2f}'.format(random_mlp.best_score_))\n",
        "# print('MLP의 랜덤서치 최고 성능 모델: {}'.format(random_mlp.best_estimator_))\n",
        "# estimator = random_mlp.best_estimator_\n",
        "# Y_pred = estimator.predict(X_test)\n",
        "\n",
        "# 결과를 CSV로 저장한다.\n",
        "submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_pred})\n",
        "# submission.to_csv('C:/python/titanic/submission.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron의 교차 검증 점수 : 73.958.\n",
            "GaussainNB의 교차 검증 점수 : 78.12\n",
            "로지스틱회귀의 교차 검증 점수 : 80.026\n",
            "LinearSVC의 교차 검증 점수 : 80.477\n",
            "SVC의 교차 검증 점수 : 82.612\n",
            "KNN의 교차 검증 점수 : 79.012\n",
            "결정트리의 교차 검증 점수 : 77.109\n",
            "랜덤포레스트의 교차 검증 점수 : 76.436\n",
            "그래디언트부스팅분류의 교차 검증 점수 : 82.612\n",
            "MLP의 교차 검증 점수 : 81.266\n",
            "SGD의 교차 검증 점수 : 73.542\n",
            "                           Model   Score\n",
            "0   Gradient Boosting Classifier  82.612\n",
            "1                            SVC  82.612\n",
            "2                            MLP  81.266\n",
            "3                     Linear SVC  80.477\n",
            "4            Logistic Regression  80.026\n",
            "5                            KNN  79.012\n",
            "6                     GaussianNB  78.120\n",
            "7                  Decision Tree  77.109\n",
            "8                  Random Forest  76.436\n",
            "9                     Perceptron  73.958\n",
            "10    Stochastic Gradient Decent  73.542\n",
            "교차 검증 점수가 가장 높은 모델은 Gradient Boosting Classifier이고 점수는 82.612이다\n"
          ]
        }
      ],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python391jvsc74a57bd069a05e2619f02e99a0b2b4f3c39701648974662958e265e04f3fa16752e75602",
      "display_name": "Python 3.9.1 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "metadata": {
      "interpreter": {
        "hash": "69a05e2619f02e99a0b2b4f3c39701648974662958e265e04f3fa16752e75602"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}